{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a45d9b",
   "metadata": {
    "papermill": {
     "duration": 0.003383,
     "end_time": "2025-03-06T07:47:42.735565",
     "exception": false,
     "start_time": "2025-03-06T07:47:42.732182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook implements a submission with Gemma 2 9B IT model with some helper code to ensure the generated SVGs conform to the submission requirements. (See the [Evaluation](https://www.kaggle.com/competitions/drawing-with-llms/overview/evaluation) page for details on the submission requirements.)\n",
    "\n",
    "To use this notebook interactively, you'll need to install some dependencies. First, *turn on* the Internet under **Session options** to the right. Then select the **Add-ons->Install Dependencies** menu above and click *Run*. A console should pop up with a running `pip` command. Wait for the dependencies to finish installing and then *turn off* the Internet before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a13422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:47:42.742710Z",
     "iopub.status.busy": "2025-03-06T07:47:42.742385Z",
     "iopub.status.idle": "2025-03-06T07:47:42.746303Z",
     "shell.execute_reply": "2025-03-06T07:47:42.745674Z"
    },
    "papermill": {
     "duration": 0.00881,
     "end_time": "2025-03-06T07:47:42.747600",
     "exception": false,
     "start_time": "2025-03-06T07:47:42.738790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6306187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:47:42.753624Z",
     "iopub.status.busy": "2025-03-06T07:47:42.753382Z",
     "iopub.status.idle": "2025-03-06T07:47:42.758057Z",
     "shell.execute_reply": "2025-03-06T07:47:42.757173Z"
    },
    "papermill": {
     "duration": 0.009132,
     "end_time": "2025-03-06T07:47:42.759371",
     "exception": false,
     "start_time": "2025-03-06T07:47:42.750239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class PromptsMixin:\n",
    "    def __init__(self):\n",
    "        self.planner_template = \"\"\"\\\n",
    "You are an expert SVG writer. You will be given a textual representation of an image.\n",
    "You will make a plan to generate an SVG that best represents the text, while respecting constraints below. \n",
    "Your plan will be used by downstream agents to generate the actual SVG.\n",
    "\n",
    "<constraints>\n",
    "* **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n",
    "* **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n",
    "</constraints>\n",
    "\n",
    "Output 5-7 bullet points on the elements you plan to use. \n",
    "DO NOT use markdown formatting except for the bullet points. NO inline code, NO emphasis, NO italics, etc\n",
    "Your plan should include elements for the description AND their specific SVG constructs.\n",
    "\n",
    "<text>{}</text>\n",
    "\"\"\"\n",
    "\n",
    "        self.writer_template = \"\"\"\\\n",
    "You are an expert SVG coder. You will be given: \n",
    "1. A textual representation of an image\n",
    "2. A plan to draw that image\n",
    "\n",
    "Use both to write SVG while respecting the following constraints.\n",
    "\n",
    "<constraints>\n",
    "* **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n",
    "* **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n",
    "</constraints>\n",
    "\n",
    "You are encouraged to utilize comments to structure your output.\n",
    "Focus on a minimum viable representation of the input description within the given constraints. \n",
    "Always give the complete SVG code with nothing omitted. Never use an ellipsis.\n",
    "\n",
    "## Output Format:\n",
    "```svg\n",
    "<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n",
    "  <circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/>\n",
    "  <rect x=\"30\" y=\"30\" width=\"40\" height=\"40\" fill=\"blue\"/>\n",
    "</svg>\n",
    "```\n",
    "\n",
    "<text>{text}</text>\n",
    "<plan>{plan}</plan>\n",
    "\"\"\"\n",
    "\n",
    "        self.revision_prompt = \"\"\"\\\n",
    "Take a deep breath. Review the plan and the generated output. Then revise the SVG.\n",
    "\"\"\"\n",
    "\n",
    "        self.reflection_user_prompt = \"\"\"\\\n",
    "Don't write SVG yet. Review and create actionable recommendations to improve the outputted SVG \\\n",
    "while respecting the constraints.\n",
    "\n",
    "## Bad Examples:\n",
    "### Not specific\n",
    "- The SVG has an invalid element.\n",
    "- The SVG is illegal and cannot render.\n",
    "\n",
    "### Not actionable\n",
    "- The SVG does not make sense.\n",
    "\n",
    "Prioritize! Output MAX 10 bullet points in order of importance. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496abed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:47:42.765363Z",
     "iopub.status.busy": "2025-03-06T07:47:42.765168Z",
     "iopub.status.idle": "2025-03-06T07:48:06.323724Z",
     "shell.execute_reply": "2025-03-06T07:48:06.323046Z"
    },
    "papermill": {
     "duration": 23.563361,
     "end_time": "2025-03-06T07:48:06.325313",
     "exception": false,
     "start_time": "2025-03-06T07:47:42.761952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import concurrent\n",
    "import io\n",
    "import logging\n",
    "import re\n",
    "import re2\n",
    "\n",
    "import cairosvg\n",
    "import kagglehub\n",
    "import torch\n",
    "from lxml import etree\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import pipeline\n",
    "from transformers.cache_utils import HybridCache\n",
    "\n",
    "svg_constraints = kagglehub.package_import('metric/svg-constraints')\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TEMPERATURE = 0.6\n",
    "TOP_P = 0.9\n",
    "\n",
    "class Model(PromptsMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        MODEL_NAME = \"google/gemma-2/Transformers/gemma-2-9b-it/2\"\n",
    "        model_path = kagglehub.model_download(MODEL_NAME)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        quantization_config_4_bit = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "        )\n",
    "        \n",
    "        self.llm = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16,  # half precision\n",
    "            quantization_config=quantization_config_4_bit,  # uncomment for quantization\n",
    "            # max_memory={0: \"15GiB\", 1: \"15GiB\"},  # Maximize each GPU usage\n",
    "            # offload_folder=\"offload\",  # For any CPU offloading\n",
    "        )\n",
    "        \n",
    "        self.default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\"\n",
    "        self.constraints = svg_constraints.SVGConstraints()\n",
    "        self.timeout_seconds = 480\n",
    "    \n",
    "        self.warmup()\n",
    "        \n",
    "        # Create pipeline after warmup\n",
    "        self.pipe = pipeline(\"text-generation\", model=self.llm, tokenizer=self.tokenizer, trust_remote_code=True, max_new_tokens=200)\n",
    "\n",
    "    def warmup(self):\n",
    "        # pulled from https://huggingface.co/google/gemma-2-9b-it (2 warm-up steps)\n",
    "        # apply the torch compile transformation\n",
    "        # Allow falling back to eager for operations that can't be compiled\n",
    "        torch._dynamo.config.suppress_errors = True\n",
    "        # But still attempt to compile as much as possible\n",
    "        # self.llm.forward = torch.compile(\n",
    "        #     self.llm.forward, \n",
    "        #     mode=\"reduce-overhead\", \n",
    "        #     fullgraph=False  # Allow partial graph compilation\n",
    "        # )\n",
    "    \n",
    "        # pre-process inputs\n",
    "        input_text = \"In two sentences ONLY, the theory of special relativity states \"\n",
    "        model_inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "        prompt_length = model_inputs.input_ids.shape[1]\n",
    "        \n",
    "        # set-up k/v cache\n",
    "        past_key_values = HybridCache(\n",
    "            config=self.llm.config,\n",
    "            max_batch_size=1,\n",
    "            max_cache_len=self.llm.config.max_position_embeddings,\n",
    "            device=self.llm.device,\n",
    "            dtype=self.llm.dtype\n",
    "        )\n",
    "        \n",
    "        # enable passing kv cache to generate\n",
    "        self.llm._supports_cache_class = True\n",
    "        self.llm.generation_config.cache_implementation = None\n",
    "        \n",
    "        # two warm-up steps\n",
    "        for idx in range(2):\n",
    "            outputs = self.llm.generate(**model_inputs, past_key_values=past_key_values, do_sample=True, temperature=1.0, max_new_tokens=128)\n",
    "            past_key_values.reset()\n",
    "        \n",
    "\n",
    "    def planner_block(self, text) -> str:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": self.planner_template.format(text)}\n",
    "        ]\n",
    "            \n",
    "        outputs = self.pipe(\n",
    "            messages,\n",
    "            max_new_tokens=512, \n",
    "            do_sample=True,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P\n",
    "        )\n",
    "        assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        logging.debug(f\"Planner: {assistant_response}\")\n",
    "        return assistant_response\n",
    "\n",
    "    def writer_block(self,\n",
    "                     text: str,\n",
    "                     plan_text: str, \n",
    "                     revision_turns=0\n",
    "    ) -> str:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": self.writer_template.format(text=text, plan=plan_text)},\n",
    "        ]\n",
    "            \n",
    "        outputs = self.pipe(\n",
    "            messages,\n",
    "            max_new_tokens=2048, \n",
    "            do_sample=True,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P\n",
    "        )\n",
    "        assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        logging.debug(f\"Writer: {assistant_response}\")\n",
    "    \n",
    "        if revision_turns:\n",
    "            revision_idx = 0\n",
    "            while revision_idx < revision_turns:\n",
    "                logging.debug(f\"Revision turn: {revision_idx+1}\")\n",
    "                revision_messages = [\n",
    "                    {\"role\": \"assistant\", \"content\": assistant_response},\n",
    "                    {\"role\": \"user\", \"content\": self.revision_prompt}\n",
    "                ]\n",
    "                messages.extend(revision_messages)        \n",
    "                outputs = self.pipe(\n",
    "                    messages,\n",
    "                    max_new_tokens=1024, \n",
    "                    do_sample=True,\n",
    "                    temperature=TEMPERATURE,\n",
    "                    top_p=TOP_P\n",
    "                )\n",
    "                assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "                logging.debug(f\"Revision: {assistant_response}\")\n",
    "                \n",
    "                revision_idx +=1\n",
    "    \n",
    "        return assistant_response\n",
    "\n",
    "    # You could try increasing `max_new_tokens`\n",
    "    def predict(self, description: str) -> str:\n",
    "        def generate_svg():\n",
    "            try:\n",
    "                plan = self.planner_block(description)\n",
    "                svg_response = self.writer_block(\n",
    "                    description, \n",
    "                    plan, \n",
    "                    revision_turns=0  # to 1 for a revision run\n",
    "                )\n",
    "\n",
    "                matches = re.findall(r\"<svg.*?</svg>\", svg_response, re.DOTALL | re.IGNORECASE)\n",
    "                if not matches:\n",
    "                    return self.default_svg\n",
    "\n",
    "                svg = matches[-1]\n",
    "                \n",
    "                svg = self.enforce_constraints(svg)\n",
    "                logging.debug('Processed SVG: %s', svg)\n",
    "                # Ensure the generated code can be converted by cairosvg\n",
    "                cairosvg.svg2png(bytestring=svg.encode('utf-8'))\n",
    "                return svg\n",
    "            except Exception as e:\n",
    "                logging.error('Exception during SVG generation: %s', e)\n",
    "                return self.default_svg\n",
    "\n",
    "        # Execute SVG generation in a new thread to enforce time constraints\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future = executor.submit(generate_svg)\n",
    "            try:\n",
    "                return future.result(timeout=self.timeout_seconds)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                logging.warning(\"Prediction timed out after %s seconds.\", self.timeout_seconds)\n",
    "                return self.default_svg\n",
    "            except Exception as e:\n",
    "                logging.error(f\"An unexpected error occurred: {e}\")\n",
    "                return self.default_svg\n",
    "\n",
    "    def enforce_constraints(self, svg_string: str) -> str:\n",
    "        \"\"\"Enforces constraints on an SVG string, removing disallowed elements\n",
    "        and attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        svg_string : str\n",
    "            The SVG string to process.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The processed SVG string, or the default SVG if constraints\n",
    "            cannot be satisfied.\n",
    "        \"\"\"\n",
    "        logging.info('Sanitizing SVG...')\n",
    "\n",
    "        try:\n",
    "            parser = etree.XMLParser(remove_blank_text=True, remove_comments=True)\n",
    "            root = etree.fromstring(svg_string, parser=parser)\n",
    "        except etree.ParseError as e:\n",
    "            logging.error('SVG Parse Error: %s. Returning default SVG.', e)\n",
    "            return self.default_svg\n",
    "    \n",
    "        elements_to_remove = []\n",
    "        for element in root.iter():\n",
    "            tag_name = etree.QName(element.tag).localname\n",
    "    \n",
    "            # Remove disallowed elements\n",
    "            if tag_name not in self.constraints.allowed_elements:\n",
    "                elements_to_remove.append(element)\n",
    "                continue  # Skip attribute checks for removed elements\n",
    "    \n",
    "            # Remove disallowed attributes\n",
    "            attrs_to_remove = []\n",
    "            for attr in element.attrib:\n",
    "                attr_name = etree.QName(attr).localname\n",
    "                if (\n",
    "                    attr_name\n",
    "                    not in self.constraints.allowed_elements[tag_name]\n",
    "                    and attr_name\n",
    "                    not in self.constraints.allowed_elements['common']\n",
    "                ):\n",
    "                    attrs_to_remove.append(attr)\n",
    "    \n",
    "            for attr in attrs_to_remove:\n",
    "                logging.debug(\n",
    "                    'Attribute \"%s\" for element \"%s\" not allowed. Removing.',\n",
    "                    attr,\n",
    "                    tag_name,\n",
    "                )\n",
    "                del element.attrib[attr]\n",
    "    \n",
    "            # Check and remove invalid href attributes\n",
    "            for attr, value in element.attrib.items():\n",
    "                 if etree.QName(attr).localname == 'href' and not value.startswith('#'):\n",
    "                    logging.debug(\n",
    "                        'Removing invalid href attribute in element \"%s\".', tag_name\n",
    "                    )\n",
    "                    del element.attrib[attr]\n",
    "\n",
    "            # Validate path elements to help ensure SVG conversion\n",
    "            if tag_name == 'path':\n",
    "                d_attribute = element.get('d')\n",
    "                if not d_attribute:\n",
    "                    logging.warning('Path element is missing \"d\" attribute. Removing path.')\n",
    "                    elements_to_remove.append(element)\n",
    "                    continue # Skip further checks for this removed element\n",
    "                # Use regex to validate 'd' attribute format\n",
    "                path_regex = re2.compile(\n",
    "                    r'^'  # Start of string\n",
    "                    r'(?:'  # Non-capturing group for each command + numbers block\n",
    "                    r'[MmZzLlHhVvCcSsQqTtAa]'  # Valid SVG path commands (adjusted to exclude extra letters)\n",
    "                    r'\\s*'  # Optional whitespace after command\n",
    "                    r'(?:'  # Non-capturing group for optional numbers\n",
    "                    r'-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?'  # First number\n",
    "                    r'(?:[\\s,]+-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?)*'  # Subsequent numbers with mandatory separator(s)\n",
    "                    r')?'  # Numbers are optional (e.g. for Z command)\n",
    "                    r'\\s*'  # Optional whitespace after numbers/command block\n",
    "                    r')+'  # One or more command blocks\n",
    "                    r'\\s*'  # Optional trailing whitespace\n",
    "                    r'$'  # End of string\n",
    "                )\n",
    "                if not path_regex.match(d_attribute):\n",
    "                    logging.warning(\n",
    "                        'Path element has malformed \"d\" attribute format. Removing path.'\n",
    "                    )\n",
    "                    elements_to_remove.append(element)\n",
    "                    continue\n",
    "                logging.debug('Path element \"d\" attribute validated (regex check).')\n",
    "        \n",
    "        # Remove elements marked for removal\n",
    "        for element in elements_to_remove:\n",
    "            if element.getparent() is not None:\n",
    "                element.getparent().remove(element)\n",
    "                logging.debug('Removed element: %s', element.tag)\n",
    "\n",
    "        try:\n",
    "            cleaned_svg_string = etree.tostring(root, encoding='unicode')\n",
    "            return cleaned_svg_string\n",
    "        except ValueError as e:\n",
    "            logging.error(\n",
    "                'SVG could not be sanitized to meet constraints: %s', e\n",
    "            )\n",
    "            return self.default_svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f05c9",
   "metadata": {
    "papermill": {
     "duration": 0.002409,
     "end_time": "2025-03-06T07:48:06.330613",
     "exception": false,
     "start_time": "2025-03-06T07:48:06.328204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code tests the above model in a local mock-up of this competition's evaluation pipeline. It runs the model on a sample of 15 instances defined in the `test.csv` file in the `kaggle_evaluation` package folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6ea82",
   "metadata": {
    "papermill": {
     "duration": 0.002354,
     "end_time": "2025-03-06T07:48:06.335411",
     "exception": false,
     "start_time": "2025-03-06T07:48:06.333057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alternatively, you could use the code below to run the model over `train.csv` and see some generated images along with some debugging info. Feel free to turn down the logging level to `INFO` if you just want to see the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331651db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:48:06.341507Z",
     "iopub.status.busy": "2025-03-06T07:48:06.341038Z",
     "iopub.status.idle": "2025-03-06T07:48:06.828596Z",
     "shell.execute_reply": "2025-03-06T07:48:06.827718Z"
    },
    "papermill": {
     "duration": 0.491995,
     "end_time": "2025-03-06T07:48:06.830034",
     "exception": false,
     "start_time": "2025-03-06T07:48:06.338039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>description</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;04c411&quot;</td><td>&quot;a starlit night over snow-covered peaks&quot;</td></tr><tr><td>&quot;215136&quot;</td><td>&quot;black and white checkered pants&quot;</td></tr><tr><td>&quot;3e2bc6&quot;</td><td>&quot;crimson rectangles forming a chaotic grid&quot;</td></tr><tr><td>&quot;61d7a8&quot;</td><td>&quot;burgundy corduroy pants with patch pockets and silver buttons&quot;</td></tr><tr><td>&quot;6f2ca7&quot;</td><td>&quot;orange corduroy overalls&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;bf3306&quot;</td><td>&quot;magenta trapezoids layered on a transluscent silver sheet&quot;</td></tr><tr><td>&quot;e2240f&quot;</td><td>&quot;gray wool coat with a faux fur collar&quot;</td></tr><tr><td>&quot;f02e39&quot;</td><td>&quot;a purple forest at dusk&quot;</td></tr><tr><td>&quot;f6790a&quot;</td><td>&quot;purple pyramids spiraling around a bronze cone&quot;</td></tr><tr><td>&quot;f9edd5&quot;</td><td>&quot;khaki triangles and azure crescents&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 2)\n",
       "┌────────┬───────────────────────────────────────────────────────────────┐\n",
       "│ id     ┆ description                                                   │\n",
       "│ ---    ┆ ---                                                           │\n",
       "│ str    ┆ str                                                           │\n",
       "╞════════╪═══════════════════════════════════════════════════════════════╡\n",
       "│ 04c411 ┆ a starlit night over snow-covered peaks                       │\n",
       "│ 215136 ┆ black and white checkered pants                               │\n",
       "│ 3e2bc6 ┆ crimson rectangles forming a chaotic grid                     │\n",
       "│ 61d7a8 ┆ burgundy corduroy pants with patch pockets and silver buttons │\n",
       "│ 6f2ca7 ┆ orange corduroy overalls                                      │\n",
       "│ …      ┆ …                                                             │\n",
       "│ bf3306 ┆ magenta trapezoids layered on a transluscent silver sheet     │\n",
       "│ e2240f ┆ gray wool coat with a faux fur collar                         │\n",
       "│ f02e39 ┆ a purple forest at dusk                                       │\n",
       "│ f6790a ┆ purple pyramids spiraling around a bronze cone                │\n",
       "│ f9edd5 ┆ khaki triangles and azure crescents                           │\n",
       "└────────┴───────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "train = pl.read_csv('/kaggle/input/drawing-with-llms/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c96a553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:48:06.836657Z",
     "iopub.status.busy": "2025-03-06T07:48:06.836431Z",
     "iopub.status.idle": "2025-03-06T07:51:57.346857Z",
     "shell.execute_reply": "2025-03-06T07:51:57.346041Z"
    },
    "papermill": {
     "duration": 230.515159,
     "end_time": "2025-03-06T07:51:57.348228",
     "exception": false,
     "start_time": "2025-03-06T07:48:06.833069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f9a0fd9a7a4e378f72434017a78483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f74c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:51:57.355516Z",
     "iopub.status.busy": "2025-03-06T07:51:57.355289Z",
     "iopub.status.idle": "2025-03-06T07:51:57.558924Z",
     "shell.execute_reply": "2025-03-06T07:51:57.558219Z"
    },
    "papermill": {
     "duration": 0.208775,
     "end_time": "2025-03-06T07:51:57.560504",
     "exception": false,
     "start_time": "2025-03-06T07:51:57.351729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "# kaggle_evaluation.test(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c96dcce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T07:51:57.567806Z",
     "iopub.status.busy": "2025-03-06T07:51:57.567519Z",
     "iopub.status.idle": "2025-03-06T07:51:57.573785Z",
     "shell.execute_reply": "2025-03-06T07:51:57.573015Z"
    },
    "papermill": {
     "duration": 0.011349,
     "end_time": "2025-03-06T07:51:57.575223",
     "exception": false,
     "start_time": "2025-03-06T07:51:57.563874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 3\n",
    "\n",
    "def generate():\n",
    "    import polars as pl\n",
    "    from IPython.display import SVG\n",
    "    import time  # Import the time module\n",
    "    \n",
    "    logging.basicConfig(level=logging.DEBUG, force=True)\n",
    "    \n",
    "    train = pl.read_csv('/kaggle/input/drawing-with-llms/train.csv')[:N_SAMPLES]\n",
    "    display(train.head())\n",
    "    svgs = []\n",
    "    for desc in train.get_column('description'):\n",
    "        start_time = time.time()  # Record start time\n",
    "        svg = model.predict(desc)\n",
    "        end_time = time.time()    # Record end time\n",
    "        elapsed_time = end_time - start_time # Calculate elapsed time\n",
    "        print(f\"Prediction time for description '{desc[:20]}...': {elapsed_time:.4f} seconds\") # Print time\n",
    "    \n",
    "        try:\n",
    "            display(SVG(svg))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "# Uncomment and run the line below to see some generated images\n",
    "# generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c996e8a",
   "metadata": {
    "papermill": {
     "duration": 0.002948,
     "end_time": "2025-03-06T07:51:57.581607",
     "exception": false,
     "start_time": "2025-03-06T07:51:57.578659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11228460,
     "sourceId": 89659,
     "sourceType": "competition"
    },
    {
     "sourceId": 224423433,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 76277,
     "modelInstanceId": 72256,
     "sourceId": 104453,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 225262,
     "modelInstanceId": 204046,
     "sourceId": 256586,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 260.839019,
   "end_time": "2025-03-06T07:52:01.040268",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-06T07:47:40.201249",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0edc904a6c8649a598ba2185017212cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "28039a6296804c4e80888be6a62f0b14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2aae7ebf321a47a0930bd02b951dc928": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "632fd99e6f324f1da05931ff5859034a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73f9a0fd9a7a4e378f72434017a78483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b56e808c9df7468e8a87059807cf3e5a",
        "IPY_MODEL_ec710f4361eb47ac97163299ba274c04",
        "IPY_MODEL_d63af5667a6d4a9287772967b9390f50"
       ],
       "layout": "IPY_MODEL_d67baca9eafa48dfa63bffd8b721a2a4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "822b6c95a65b4889939f99864bcb2e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9bf728666b734363befe9a5484bf4433": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b56e808c9df7468e8a87059807cf3e5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_632fd99e6f324f1da05931ff5859034a",
       "placeholder": "​",
       "style": "IPY_MODEL_0edc904a6c8649a598ba2185017212cb",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "d63af5667a6d4a9287772967b9390f50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9bf728666b734363befe9a5484bf4433",
       "placeholder": "​",
       "style": "IPY_MODEL_822b6c95a65b4889939f99864bcb2e2b",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [03:20&lt;00:00, 47.24s/it]"
      }
     },
     "d67baca9eafa48dfa63bffd8b721a2a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec710f4361eb47ac97163299ba274c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2aae7ebf321a47a0930bd02b951dc928",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_28039a6296804c4e80888be6a62f0b14",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
